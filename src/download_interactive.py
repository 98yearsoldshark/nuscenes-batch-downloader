import requests
import os
import hashlib
import json
from tqdm import tqdm

# ================= é…ç½®è¯´æ˜ =================
# ä¸è¦åœ¨ä»£ç é‡Œç¡¬ç¼–ç  Tokenï¼Œæ¨èï¼š
# 1) ç¯å¢ƒå˜é‡ï¼šNUSCENES_TOKEN
# 2) é…ç½®æ–‡ä»¶ï¼šconfig.jsonï¼ˆå·²åœ¨ .gitignore ä¸­å¿½ç•¥ï¼‰
#    - bearer_token: ä½ çš„ token
#    - region: 'asia' ç­‰ï¼ˆé»˜è®¤ asiaï¼‰
#    - output_dir: ä¸‹è½½ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ ./output_filesï¼‰
# ===========================================

DEFAULT_CONFIG_PATH = "config.json"
DEFAULT_OUTPUT_DIR = "./output_files"
DEFAULT_REGION = "asia"

ENV_TOKEN_KEY = "NUSCENES_TOKEN"
ENV_REGION_KEY = "NUSCENES_REGION"
ENV_OUTPUT_DIR_KEY = "NUSCENES_OUTPUT_DIR"

OUTPUT_DIR = DEFAULT_OUTPUT_DIR
REGION = DEFAULT_REGION

# å®Œæ•´çš„æ–‡ä»¶åˆ—è¡¨å’ŒMD5
FILES_CONFIG = {
    "v1.0-test_meta.tgz": "b0263f5c41b780a5a10ede2da99539eb",
    "v1.0-test_blobs.tgz": "e065445b6019ecc15c70ad9d99c47b33",
    "v1.0-trainval01_blobs.tgz": "cbf32d2ea6996fc599b32f724e7ce8f2",
    "v1.0-trainval02_blobs.tgz": "aeecea4878ec3831d316b382bb2f72da",
    "v1.0-trainval03_blobs.tgz": "595c29528351060f94c935e3aaf7b995",
    "v1.0-trainval04_blobs.tgz": "b55eae9b4aa786b478858a3fc92fb72d",
    "v1.0-trainval05_blobs.tgz": "1c815ed607a11be7446dcd4ba0e71ed0",
    "v1.0-trainval06_blobs.tgz": "7273eeea36e712be290472859063a678",
    "v1.0-trainval07_blobs.tgz": "46674d2b2b852b7a857d2c9a87fc755f",
    "v1.0-trainval08_blobs.tgz": "37524bd4edee2ab99678909334313adf",
    "v1.0-trainval09_blobs.tgz": "a7fcd6d9c0934e4052005aa0b84615c0",
    "v1.0-trainval10_blobs.tgz": "31e795f2c13f62533c727119b822d739",
    "v1.0-trainval_meta.tgz": "537d3954ec34e5bcb89a35d4f6fb0d4a",
}

def load_config(path=DEFAULT_CONFIG_PATH):
    if not os.path.exists(path):
        return {}

    try:
        with open(path, "r", encoding="utf-8") as f:
            raw = f.read().strip()
        return json.loads(raw) if raw else {}
    except Exception as e:
        print(f"[WARN] è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {path} ({e})")
        return {}

def resolve_settings():
    config = load_config()

    token = (os.getenv(ENV_TOKEN_KEY) or config.get("bearer_token") or config.get("token") or "").strip()
    region = (os.getenv(ENV_REGION_KEY) or config.get("region") or DEFAULT_REGION).strip() or DEFAULT_REGION
    output_dir = (os.getenv(ENV_OUTPUT_DIR_KEY) or config.get("output_dir") or DEFAULT_OUTPUT_DIR).strip() or DEFAULT_OUTPUT_DIR

    if not token:
        token = input("è¯·è¾“å…¥ nuScenes Bearer Tokenï¼ˆä¸ä¼šå†™å…¥æ–‡ä»¶ï¼‰: ").strip()
    if not token:
        raise ValueError("Token ä¸ºç©ºï¼Œè¯·å…ˆé€šè¿‡ç¯å¢ƒå˜é‡æˆ– config.json é…ç½®ã€‚")

    return token, region, output_dir

def get_headers(bearer_token):
    return {
        'Authorization': f'Bearer {bearer_token}',
        'Content-Type': 'application/json',
    }

def stage_1_probe_urls(bearer_token):
    """ç¬¬ä¸€é˜¶æ®µï¼šæŸ¥çœ‹å“ªäº›å¯ä»¥ä¸‹è½½ (è·å–ä¸‹è½½é“¾æ¥)"""
    print(f"\n--- [é˜¶æ®µ 1/3] æ­£åœ¨æ¢æµ‹æœåŠ¡å™¨èµ„æº (Region: {REGION}) ---")
    valid_urls = {}
    
    headers = get_headers(bearer_token)
    # å¢åŠ ä¸€ä¸ª tqdm è¿›åº¦æ¡æ˜¾ç¤ºæ¢æµ‹è¿›åº¦
    pbar = tqdm(FILES_CONFIG.items(), desc="è·å–ä¸‹è½½é“¾æ¥", unit="file")
    
    for filename, md5 in pbar:
        api_url = f'https://o9k5xn5546.execute-api.us-east-1.amazonaws.com/v1/archives/v1.0/{filename}?region={REGION}&project=nuScenes'
        try:
            # è®¾ç½®è¶…æ—¶ï¼Œé˜²æ­¢å¡æ­»
            response = requests.get(api_url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if 'url' in data:
                    valid_urls[filename] = {
                        'url': data['url'],
                        'md5': md5,
                        'local_path': os.path.join(OUTPUT_DIR, filename)
                    }
            elif response.status_code == 403 or response.status_code == 401:
                pbar.write(f"âŒ {filename}: è®¤è¯å¤±è´¥ (Tokenå¯èƒ½è¿‡æœŸ)")
            else:
                pbar.write(f"âš ï¸ {filename}: è¯·æ±‚é”™è¯¯ code {response.status_code}")
        except Exception as e:
            pbar.write(f"âŒ {filename}: ç½‘ç»œè¿æ¥é”™è¯¯")
    
    print(f"\nâœ… æ¢æµ‹å®Œæˆã€‚æˆåŠŸè·å– {len(valid_urls)}/{len(FILES_CONFIG)} ä¸ªæ–‡ä»¶çš„ä¸‹è½½åœ°å€ã€‚")
    return valid_urls

def stage_2_select_files(valid_urls):
    """ç¬¬äºŒé˜¶æ®µï¼šç”¨æˆ·é€‰æ‹©ä¸‹è½½åˆ—è¡¨"""
    if not valid_urls:
        print("æ²¡æœ‰å¯ç”¨çš„ä¸‹è½½é“¾æ¥ï¼Œè¯·æ£€æŸ¥ Token æˆ–ç½‘ç»œã€‚ç¨‹åºé€€å‡ºã€‚")
        return []

    print(f"\n--- [é˜¶æ®µ 2/3] é€‰æ‹©è¦ä¸‹è½½çš„æ–‡ä»¶ ---")
    file_list = list(valid_urls.keys())
    
    # æ‰“å°èœå•
    print(f"{'ID':<4} | {'æ–‡ä»¶å':<30} | {'çŠ¶æ€'}")
    print("-" * 50)
    for idx, name in enumerate(file_list):
        local_path = valid_urls[name]['local_path']
        status = "å·²å­˜åœ¨" if os.path.exists(local_path) else "æœªä¸‹è½½"
        print(f"{idx:<4} | {name:<30} | {status}")
    
    print("-" * 50)
    print("æ“ä½œæç¤º:")
    print("  - è¾“å…¥ 'all' ä¸‹è½½æ‰€æœ‰æ–‡ä»¶")
    print("  - è¾“å…¥ ID æ•°å­— (ç”¨ç©ºæ ¼åˆ†éš”) ä¸‹è½½æŒ‡å®šæ–‡ä»¶ (ä¾‹å¦‚: 0 1 5)")
    print("  - è¾“å…¥ 'q' é€€å‡º")
    
    choice = input("\nè¯·è¾“å…¥æ‚¨çš„é€‰æ‹©: ").strip().lower()
    
    selected_files = []
    
    if choice == 'q':
        return []
    elif choice == 'all':
        selected_files = file_list
    else:
        try:
            indices = choice.split()
            for i in indices:
                idx = int(i)
                if 0 <= idx < len(file_list):
                    selected_files.append(file_list[idx])
                else:
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆ ID: {idx}")
        except ValueError:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·åªè¾“å…¥æ•°å­—ã€‚")
            return []
            
    print(f"âœ… å·²é€‰æ‹© {len(selected_files)} ä¸ªæ–‡ä»¶å‡†å¤‡ä¸‹è½½/æ ¡éªŒã€‚")
    return selected_files

def check_md5(filepath, expected_md5):
    """è®¡ç®—å¹¶æ¯”å¯¹ MD5"""
    print(f"æ­£åœ¨æ ¡éªŒå®Œæ•´æ€§: {os.path.basename(filepath)} ...")
    md5obj = hashlib.md5()
    file_size = os.path.getsize(filepath)
    
    # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºæ ¡éªŒè¿‡ç¨‹
    with open(filepath, 'rb') as f:
        with tqdm(total=file_size, unit='B', unit_scale=True, unit_divisor=1024, desc="Verify", ascii=True) as pbar:
            for chunk in iter(lambda: f.read(4096), b""):
                md5obj.update(chunk)
                pbar.update(len(chunk))
                
    current_md5 = md5obj.hexdigest()
    return current_md5 == expected_md5

def stage_3_download_and_verify(selected_names, valid_urls):
    """ç¬¬ä¸‰é˜¶æ®µï¼šä¸‹è½½å¹¶æ ¡éªŒ"""
    print(f"\n--- [é˜¶æ®µ 3/3] å¼€å§‹ä¸‹è½½ä¸éªŒè¯ ---")
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    for name in selected_names:
        info = valid_urls[name]
        url = info['url']
        save_path = info['local_path']
        expected_md5 = info['md5']
        
        # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(save_path):
            print(f"\nğŸ“ æ–‡ä»¶å·²å­˜åœ¨: {name}")
            # è¯¢é—®æ˜¯å¦è¦†ç›–æˆ–ä»…æ ¡éªŒ
            # ä¸ºäº†è‡ªåŠ¨åŒ–ï¼Œè¿™é‡Œé€»è¾‘è®¾ä¸ºï¼šå­˜åœ¨åˆ™ç›´æ¥æ ¡éªŒï¼Œæ ¡éªŒå¤±è´¥åˆ™è¯¢é—®é‡ä¸‹
            if check_md5(save_path, expected_md5):
                print(f"âœ… {name} æ ¡éªŒé€šè¿‡ (æ— éœ€é‡æ–°ä¸‹è½½)")
                continue
            else:
                print(f"âŒ {name} æ ¡éªŒå¤±è´¥ (æ–‡ä»¶æŸå)")
                retry = input("æ˜¯å¦é‡æ–°ä¸‹è½½è¯¥æ–‡ä»¶? (y/n): ").lower()
                if retry != 'y':
                    continue
                # åˆ é™¤æ—§æ–‡ä»¶å‡†å¤‡é‡ä¸‹
                os.remove(save_path)
        
        # 2. ä¸‹è½½æ–‡ä»¶
        print(f"\nâ¬‡ï¸ æ­£åœ¨ä¸‹è½½: {name}")
        try:
            response = requests.get(url, stream=True)
            # å¤„ç† tgz å¯èƒ½å˜æˆ tar çš„æƒ…å†µ (AWS ç‰¹æ€§)
            content_type = response.headers.get('Content-Type', '')
            if content_type == 'application/x-tar' and save_path.endswith('.tgz'):
                save_path = save_path.replace('.tgz', '.tar')
            
            total_size = int(response.headers.get('Content-Length', 0))
            
            with open(save_path, 'wb') as file, tqdm(
                total=total_size, unit='B', unit_scale=True, unit_divisor=1024, desc=name, ascii=True
            ) as pbar:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        file.write(chunk)
                        pbar.update(len(chunk))
            
            # 3. ä¸‹è½½åç«‹å³æ ¡éªŒ
            if check_md5(save_path, expected_md5):
                print(f"âœ… {name} ä¸‹è½½å¹¶æ ¡éªŒæˆåŠŸï¼")
            else:
                print(f"âŒ {name} ä¸‹è½½åæ ¡éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œç¨³å®šæ€§ã€‚")
                
        except Exception as e:
            print(f"âŒ ä¸‹è½½å‡ºé”™ {name}: {e}")

def main():
    global OUTPUT_DIR, REGION

    try:
        bearer_token, region, output_dir = resolve_settings()
    except Exception as e:
        print(f"[ERROR] {e}")
        return

    REGION = region
    OUTPUT_DIR = output_dir
    print(f"å½“å‰é…ç½®: region={REGION}, output_dir={OUTPUT_DIR}")

    # é˜¶æ®µ 1
    valid_urls = stage_1_probe_urls(bearer_token)
    
    # é˜¶æ®µ 2
    selected_files = stage_2_select_files(valid_urls)
    
    # é˜¶æ®µ 3
    if selected_files:
        stage_3_download_and_verify(selected_files, valid_urls)
    else:
        print("æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ã€‚")
    
    print("\næ‰€æœ‰ä»»åŠ¡ç»“æŸã€‚")
    input("æŒ‰å›è½¦é”®é€€å‡º...")

if __name__ == "__main__":
    main()
